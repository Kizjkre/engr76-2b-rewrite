{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7cf98e778fdc37",
   "metadata": {},
   "source": [
    "# ENGR 76 Project 2b: Filtering and Frequency-division multiplexing\n",
    "\n",
    "_Due: May 30, 2025 at 16:00 PDT_\n",
    "\n",
    "<font color='blue'>**YOUR STANFORD EMAIL:**</font>     @stanford.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f89580a352af40",
   "metadata": {},
   "source": [
    "If your transmission is the only sound in the room, then the receiver can just listen to it and decode it to recover the message, as you did in Project 2a. But in reality, we never have such a happy monopoly on the transmission environment. Rather, the receiver will have to deal with other sounds, like other background noise, conversations or other transmitters. Any sound that isn't the transmitted signal is called _noise_. This week, we'll explore how filtering can be used to remove noise and extract the signal.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Wireless communication, including 4G, Wi-Fi, Bluetooth, FM radio and GPS signals, has the same problem—both from other wireless transmitters and from other sources of electromagnetic energy. The techniques they use to extract their signal of interest are similar.\n",
    "</div>\n",
    "\n",
    "In this project, you will:\n",
    "\n",
    "- Establish how to work with the FFT as a practical approximation for a signal's spectrum\n",
    "- Inspect the spectra of your transmitted OOK signal, and your received one, with and without noise\n",
    "- Apply filtering to the received noisy signal and show that filtering improves the bit error rate\n",
    "- Investigate how different frequency bands can be used for independent transmissions\n",
    "- Implement frequency multiplexing to increase the data rate of your system\n",
    "- Consider how frequency multiplexing can be used to allow several systems to transmit in the same space\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"color:black;\">\n",
    "    <p>\n",
    "        <strong>Where we are in Project 2.</strong>\n",
    "    </p>\n",
    "    <p style=\"text-align: center;\">\n",
    "        <img src=\"img/proj2b-where.png\" style=\"height: 84px;\" />\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"color: black;\"><strong>Answer formatting:</strong> As usual, we've left <code>&gt; YOUR ANSWER HERE</code> in cells where we want you to type in answer. To do so, double-click the cell, and please leave the <code>&gt;</code> there (and start each paragraph with <code>&gt;</code>) so that the blockquote bar on the left remains next to your answer.</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">Throughout Project 2, you may reuse some recorded signals across different code cells. To prevent loading incorrect signals, <b>pay additional attention to your variable names to ensure they are not accidentally overwritten.</b></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b7974614bd6d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:12.549526Z",
     "start_time": "2025-05-22T21:08:12.484456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Packages you should already have installed, to be imported:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)  # make the graphs wider\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "# setting up the channels\n",
    "save_wav = False #SET TO TRUE IF AUDIO IS NOT WORKING\n",
    "from channel import Channel, save\n",
    "from functools import partial\n",
    "\n",
    "channel = Channel()\n",
    "channel0 = partial(channel.transmit, save_wav=save_wav)\n",
    "channel1 = partial(channel.transmit, talking=True, save_wav=save_wav)\n",
    "channel2 = partial(channel.transmit, clap=True, save_wav=save_wav)\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104d756f06e2e13",
   "metadata": {},
   "source": [
    "# Part 1: Getting to know the FFT (10 points)\n",
    "\n",
    "The _fast Fourier transform_ (FFT) is an algorithm for the _discrete Fourier transform_ (DFT), which is a version of the Fourier transform suitable for discrete-time, finite-length signal. We use FFT throughout this project to obtain the spectrum of time-domain signals.\n",
    "\n",
    "Technically, the FFT works on discrete-time signals,\n",
    "$$x[n], \\quad n = 0, \\dots, L-1,$$\n",
    "and returns a frequency-domain representation that is one more than half the length. We can call this $x_\\mathcal F$:\n",
    "$$x_\\mathcal{F}[n], \\quad n = 0, \\dots, \\lfloor L/2 \\rfloor.$$\n",
    "\n",
    "However, we often want to use the FFT as an **approximation** to the continuous-time Fourier transform. For example, say that $x[n]$ was a sampled version of a continuous-time signal $\\tilde x(t)$ at sampling frequency $f_s$ ,\n",
    "\n",
    "$$x[n] = \\tilde x(t[n]), \\qquad t[n] = \\frac{n}{f_s}.$$\n",
    "\n",
    "Recall from last week that to plot this signal using `plt.plot()` in a way that makes sense for “the real world”, we plot the time vector $t[n]$ against the signal vector $x[n]$. Similarly, when working with the FFT $x_\\mathcal{F}[n]$, we'll want to plot it against some sort of “frequency vector”\n",
    "$$f[n], \\quad n = 0, \\dots, \\lfloor L/2 \\rfloor.$$\n",
    "\n",
    "Our goal in this part is to establish how to think about what $f[n]$ should be.\n",
    "\n",
    "### FFT of a pure tone\n",
    "\n",
    "Let's start with a **pure tone**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406effadacd1236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:12.700155Z",
     "start_time": "2025-05-22T21:08:12.556420Z"
    }
   },
   "outputs": [],
   "source": [
    "# feel free to play with these numbers and then re-run subsequent cells\n",
    "tmax = 0.1  # end of signal in \"real\" time (seconds)\n",
    "fs = 44100  # sampling frequency\n",
    "f = 1000  # frequency of tone\n",
    "t = np.arange(0, tmax, 1 / fs)  # time vector t[n]\n",
    "x = np.sin(2 * np.pi * f * t)  # signal vector x[n]\n",
    "\n",
    "# plot signal in time domain\n",
    "plt.plot(t, x)\n",
    "plt.xlabel('Continuous-time variable, t', size=18)\n",
    "plt.ylabel('Continuous x(t)', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead8784cf8b1865",
   "metadata": {},
   "source": [
    "We can take the FFT using the `rfft()` function, which is in the the `scipy.fft` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e883b873aaba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:12.738381Z",
     "start_time": "2025-05-22T21:08:12.735255Z"
    }
   },
   "outputs": [],
   "source": [
    "# import relevant functions\n",
    "from scipy.fft import rfft, irfft, rfftfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb8e8cb907efc8",
   "metadata": {},
   "source": [
    "If you inspect the spectrum `rfft(x)`, you'll notice that its entries are complex. In class we had the convention of having separate $a_j$, $b_j$ coefficients for sine and cosine. In the projects we will combine them into a single complex value $x_\\mathcal{F}[j] = b_j + ia_j$. For $j=0$, the value is guaranteed to be real as we only have $b_0$. To visualize it effectively as a plot, it's common to take its absolute value (also known as its modulus). That is, instead of plotting $x_\\mathcal{F}[n]$ (called `x_fft` below), we instead plot $|x_\\mathcal{F}[n]|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1947d875778270b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:12.845305Z",
     "start_time": "2025-05-22T21:08:12.776739Z"
    }
   },
   "outputs": [],
   "source": [
    "x_fft = rfft(x)\n",
    "print(x_fft.dtype)\n",
    "plt.plot(np.abs(x_fft))\n",
    "plt.ylabel('Amplitude', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195da96d4a5f890c",
   "metadata": {},
   "source": [
    "One problem: The above code plots with respect to frequency \"indices\" $n$, which aren't very meaningful here. That spike should be at whatever `f` was set to above.\n",
    "\n",
    "<div class=\"alert alert-warning\">This is a key distinction between our work in this project, and our study of the DCT for images in Project 1b. In Project 1b, the “duration” of the signal (<i>i.e.</i> size of the image) had no physical meaning, so we ignored the units. Here, time is <em>measured in seconds</em> and frequency is <em>expressed in Hertz</em> (the reciprocal of seconds), so we have to be more precise with our handling of frequencies.</div>\n",
    "\n",
    "Whenever we need to plot the FFT of a signal, we also need to generate a vector of frequencies, so that the horizontal axis is scaled appropriately. To establish the scaling, note the following:\n",
    "- The number of elements in the FFT output is half the length of the original signal $L$\n",
    "- The highest frequency that the original signal can capture is half the sampling frequency $f_s$\n",
    "\n",
    "The frequency vector is therefore given by\n",
    "\n",
    "$$f[n] = \\frac{f_s/2}{L/2} \\cdot n = \\frac{f_s}{L} \\cdot n = \\frac{1}{L T_s} \\cdot n, \\qquad \\text{for } n = 0, \\dots, \\lfloor L/2 \\rfloor.$$\n",
    "\n",
    "where $L$ is the length of the signal vector $x[n]$, $f_s$ is the sampling frequency, and $T_s = 1/f_s$ is the sampling period.\n",
    "\n",
    "NumPy provides a convenience function that does this for us. It's called `rfftfreq`, and it takes two arguments: the length of the original signal $L$, and the sampling period $T_s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d481dcda34f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:13.104871Z",
     "start_time": "2025-05-22T21:08:12.913063Z"
    }
   },
   "outputs": [],
   "source": [
    "Ts = 1 / fs\n",
    "f_fft = rfftfreq(x.size, Ts)  # equivalent to: np.arange(x_fft.size) * fs / x.size\n",
    "x_fft = rfft(x)\n",
    "\n",
    "plt.plot(f_fft, np.abs(x_fft))\n",
    "plt.xlabel(\"Frequency (Hz)\", size=18)\n",
    "plt.ylabel(\"Amplitude\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc5dab95bcc721",
   "metadata": {},
   "source": [
    "So to summarize, to use the FFT as an approximation for the continuous-time Fourier transform, we do what's in the above cell.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <p><strong>More than you needed to know:</strong> The <code>r</code> in <code>rfft()</code> stands for “real”, signalling that <code>rfft()</code> computes the FFT on the assumption that the signal is real (<i>i.e.</i>, without imaginary part), which ours is. The frequency-domain representation (FFT output), however, is still complex (<i>i.e.</i>, has an imaginary part).</p>\n",
    "    <p>Then what does the real assumption buy us? The standard <code>fft()</code> computes the FFT assuming that the input might be complex. This gives rise to “negative frequencies”, which are beyond the scope of this course. However, if the input is real, then the negative frequencies form a symmetry with the positive frequencies. This renders the negative frequencies redundant, so <code>rfft()</code> just doesn't compute them.</p>\n",
    "    <p>The frequency-domain representation is complex to account for both the amplitude and phase of frequency components. The magnitude (a.k.a. absolute value, modulus) repreesnts the amplitude, and the argument (a.k.a. angle) represents the phase. In this project, we will only be interested in inspecting the magnitude of frequency components. However, it's necessary to retain the whole complex number to be able to do the inverse FFT, which we'll do next.</p>\n",
    "</div>\n",
    "\n",
    "### Inverse FFT\n",
    "\n",
    "The function computing the inverse FFT is `irfft()`.\n",
    "\n",
    "Like `rfft()`, `irfft()` doesn't itself know anything, or need to know anything, about sampling. It just carries out the inverse FFT algorithm on frequency components, presumably indexed by integers. The corresponding time vector $t[n]$ is then the same time vector that we started with, $t[n] = nT_s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685338f6eef9464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:13.283047Z",
     "start_time": "2025-05-22T21:08:13.112414Z"
    }
   },
   "outputs": [],
   "source": [
    "x_recovered = irfft(x_fft)\n",
    "# just use the same `t` from before\n",
    "plt.plot(t, x_recovered)\n",
    "plt.xlabel('t', size=18)\n",
    "plt.ylabel('Recovered x(t)', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641da86f7633683f",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 1.1.</span> Choose two other frequencies, and make a signal with exactly those two frequency components (by adding two pure tones together). Plot the FFT vector $x_\\mathcal{F}[n]$ against the correct frequency vector $f[n]$, such that the spikes are in the right place. Plot the result of the inverse FFT to verify it recovers the original signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad7f65d269a832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:13.791309Z",
     "start_time": "2025-05-22T21:08:13.687635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell for Question 1.1\n",
    "# plot frequency spectrum\n",
    "f_fft = None\n",
    "x_fft = None\n",
    "##### YOUR CODE HERE ######\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e6c5286d076bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:13.963111Z",
     "start_time": "2025-05-22T21:08:13.826475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell for Question 1.1\n",
    "# plot time domain signal\n",
    "##### YOUR CODE HERE ######\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc82743-6190-4c77-9d49-cca641317a61",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 1.2.</span> Is the spectrum plot what you expected? How many peaks do you see, and at what frequencies?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e32c47-e86c-42a8-9ea2-4e677a87c8ae",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7212d762af3b2d",
   "metadata": {},
   "source": [
    "# Part 2: The spectrum of the transmitted signal (20 points)\n",
    "\n",
    "We're now in a position to begin our investigation of the spectrum of our transmitted OOK signal. Let's start with the **baseband** (unmodulated) signal.\n",
    "\n",
    "<div class=\"alert alert-info\"><strong>Terminology:</strong> In this project, the <em>baseband signal</em>, <em>unmodulated signal</em> and <em>envelope signal</em> are all the same thing. Similarly, <em>passband signal</em> and <em>modulated signal</em> refer to the same thing. (In other contexts, there might be subtle differences between these terms, but in this project, there aren't.)</div>\n",
    "\n",
    "### Spectrum of baseband (unmodulated, envelope) signal\n",
    "\n",
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 2.1.</span> Use your code from Project 2a to generate a **baseband** (envelope) signal for a randomly generated message. \n",
    "\n",
    "**IMPORTANT NOTE**: Use the `rfft()` and `rfftfreq()` functions to plot the magnitude (`np.abs()`) of its spectrum. This will be required for all subsequent questions where we ask you to plot the spectrum of a signal.\n",
    "\n",
    "Use a data rate of 300 bits/second. Your message should be of a length that the entire transmission takes around 6 seconds.\n",
    "\n",
    "**Zooming in on plots:** If you want to zoom in horizontally on the plot, you can use the command <code>plt.xlim(xmin, xmax)</code> to specify the limits of the x-axis. For example, `plt.xlim(0, 10)` will restrict the plot to between 0 and 10 on the x-axis. This can allow you to zoom in on the parts of the spectrum that are more interesting. Similarly, you can use <code>plt.ylim(ymin, ymax)</code> to zoom in on the y-axis (vertically). This might allow you to more closely inspect the nonzero parts of the spectrum that aren't the big main spike.\n",
    "\n",
    "To get a better understanding of the spectrum, you will require to zoom in horizontally. Please present **both** the original plot **and** the zoomed in plot. (It's okay to duplicate plotting code between cells to make this work.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c67aa028f9645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:14.000484Z",
     "start_time": "2025-05-22T21:08:13.997662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 2.1.\n",
    "# Spectrum of the baseband (envelope) signal.\n",
    "rate = 300\n",
    "message = rng.integers(0, 2, 1800)\n",
    "message = np.insert(message, 0, 1)  # always start the message with a 1\n",
    "baseband = None #replace this\n",
    "# As always, add as many cells as you need to show what you want to show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb1894-503e-4119-ac14-a7689e454759",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 2.2.</span> Examine the spectrum plot (with appropriate zooming-in) for the baseband signal and comment on the shape of the spectrum. Is this similar to what we learnt in class? At what frequency, does the spectrum first become zero? How is this related to the data rate we set above? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251ba4f-c555-47b4-b1b7-29989930034a",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6921eb322fa394",
   "metadata": {},
   "source": [
    "### Spectrum of modulated (passband) signal\n",
    "\n",
    "Now modulate the signal and inspect its spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a395463e392a73",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 2.3.</span> Use your code from Project 2a to **modulate** your baseband signal at a carrier frequency of 1800 Hz to arrive at the **modulated (passband) signal** (_i.e._, multiply by a pure tone at your the carrier frequency), and plot the spectrum of the modulated signal.\n",
    "\n",
    "<div class=\"alert alert-success\" style=\"color: black;\"><strong>General notes on plots.</strong> In all spectrum plots in this project, you should:\n",
    "    <ul>\n",
    "        <li>plot only the magnitude of the spectrum, <i>i.e.</i> take the <code>np.abs()</code> of the (complex) spectrum before plotting, and</li>\n",
    "        <li>feel at liberty to zoom in to the plot using <code>plt.xlim()</code> (and <code>plt.ylim()</code> if you like), but please always present the original zoomed out plot as well, so we can see what you're zooming into.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee7e7f69ad72a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:14.304325Z",
     "start_time": "2025-05-22T21:08:14.301441Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 2.3.\n",
    "fc = 1800\n",
    "# Spectrum of passband signal.\n",
    "# YOUR CODE HERE\n",
    "# As always, add as many cells as you need to show what you want to show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef84bc8-f434-41e8-897a-e11c2b08c5b4",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 2.4.</span> Examine the spectrum plot (with appropriate zooming-in) for the modulated signal and comment on the shape of the spectrum. \n",
    "- Is this similar to what we learnt in class? What frequency is the spectrum centered at (i.e., the frequency at which the amplitude of the spectrum is the largest)?\n",
    "- In class, we defined the approximate band the signal lies in as the the region between the first zero corssings on either side of the peak. What is the approximate band the signal lies in? Does this match our choice of rate above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7897826-0d1b-4a3c-b4ee-a97961796af1",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a41acf377e9815",
   "metadata": {},
   "source": [
    "# Part 3: The spectrum of the received signal (20 points)\n",
    "\n",
    "It's useful to understand the spectrum of the transmitted signal because it gives us an idea of what to expect from a \"perfect received signal\" (which is, in an ideal world, just a scaled version of the transmitted signal). In this part, we'll inspect the spectrum of the received signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00743da7e7a193b",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 3.1.</span> We have given you the code to transmit and receive your modulated signal (using `channel0()`). Recall that we add silence before passing the signal through the channel to allow the whole signal to be captured by the receiver.\n",
    "\n",
    "Please plot the spectrum of the received signal. \n",
    "\n",
    "_Note:_ The silence is added after the signal to make sure the entire OOK signal is recorded. However, you don't need to truncate the signal to detect its starting point accurately—just take the FFT of the whole thing. Note that this means your frequency vector $f[n]$ (generated by `rfftfreq()`) will be different to the one you used to plot the spectrum in Part 2, as the signal is longer now.\n",
    "\n",
    "<div class=\"alert alert-info\">Reminder: You can zoom in using <code>plt.xlim()</code> and <code>plt.ylim()</code>, which you might do to look more closely at the “interesting” parts of the spectrum. It's okay to zoom in vertically in a way that pushes the main spike off the scale, if you want to look at other activity.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306bc454101bf221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:14.967656Z",
     "start_time": "2025-05-22T21:08:14.955265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now that we don't need to separately use the baseband and modulated signals,\n",
    "# you can directly use the functions from 2a.\n",
    "# Feel free to replace with your answers from 2a.\n",
    "def add_silence(signal: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Adds an appropriate amount of silence to the signal.\n",
    "        - signal: 1-D array of floats\n",
    "    Output variables:\n",
    "        - new_signal: 1-D array of floats\n",
    "    \"\"\"\n",
    "    silence = 1  # seconds\n",
    "    new_signal = np.append(signal, np.zeros(int(silence * fs)))\n",
    "    return new_signal\n",
    "\n",
    "\n",
    "def generate_modulated_signal(message: np.ndarray, rate: float, fc: float) -> np.ndarray:\n",
    "    \"\"\" Generate the modulated signal.\n",
    "    Input variables:\n",
    "        - message: 1-D array of ints\n",
    "        - rate:    data rate in bits per second\n",
    "        - fc:      carrier frequency in Hz\n",
    "    Output variables:\n",
    "        - signal: modulated signal as 1-D array of floats\n",
    "    \"\"\"\n",
    "    T = 1 / rate\n",
    "    k = len(message)\n",
    "    t = np.arange(int(k*T*fs))/fs\n",
    "    envelope = message[np.floor(t / T).astype(int)]\n",
    "    signal = np.sin(2 * np.pi * fc * t) * envelope\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105088c3cafab9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:15.369958Z",
     "start_time": "2025-05-22T21:08:15.204594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 3.1\n",
    "# Spectrum of the received signal.\n",
    "rate = 300\n",
    "fc = 1800\n",
    "message = rng.integers(0, 2, 1800)\n",
    "message = np.insert(message, 0, 1)  # always start the message with a 1\n",
    "\n",
    "x = generate_modulated_signal(message, rate, fc)\n",
    "x_extended = add_silence(x)\n",
    "y = channel0(x_extended)\n",
    "\n",
    "##### YOUR CODE HERE ######\n",
    "###########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd09dc30ee9225",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 3.2.</span> Comment on how this is similar to and different from the spectrum of the transmitted passband signal you found in Question 2.3. For example—is the spike in the same place, are there additional components or absent components?\n",
    "\n",
    "_WHAT WE EXPECT_: a short answer with 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d83a2de5e28f87",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8ad44cbf6d881",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 3.3.</span> The following cell records noise from `channel1` (the one while talking) for 6 seconds.\n",
    "\n",
    "You should first plot the talking noise (in the time domain). This will help you understand how an audio of someone talking looks like before. Then plot the spectrum of talking noise in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c452deb35bc779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:16.019084Z",
     "start_time": "2025-05-22T21:08:15.871352Z"
    }
   },
   "outputs": [],
   "source": [
    "# You don't have to change anything here. You can just run the cell.\n",
    "duration = 6\n",
    "noise = channel1(np.zeros(duration * fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845405fd-8183-48e5-b075-1180d5f12ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3.3 \n",
    "# plot the signal in the time domain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c949501dae312b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:16.055688Z",
     "start_time": "2025-05-22T21:08:16.053024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 3.3.\n",
    "# Spectrum of the \"talking noise\" recording."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852c5c2-c991-43ce-ad26-3483898b0c8e",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 3.4.</span> We are transmitting the  signal through `channel1`.\n",
    "Plot the spectrum of your received signal in the following cell.\n",
    "\n",
    "What is the relationship between this spectrum and the ones in Questions 3.3 and 2.3?\n",
    "\n",
    "_WHAT WE EXPECT_: a short answer with 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d764cfcd-624e-4735-9a02-f619f387d1c6",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae44deb-ba11-454d-87e2-2d92a606142a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">You may reuse the received signal in the subsequent questions, so to prevent error, <b> we suggest you to use a unique variable to store it </b> (e.g.,  <code>y_talking</code>).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7519ac53-7918-4685-8c5c-ed4205ebf71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3.4\n",
    "y_talking = channel1(x_extended)\n",
    "\n",
    "\n",
    "###### YOUR CODE HERE ##########\n",
    "\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db9407d4d2e864",
   "metadata": {},
   "source": [
    "# Part 4: Filtering to extract the signal of interest (35 points)\n",
    "\n",
    "Recall from Project 1b that a **filter** is an operation that extracts some frequency components, and sets all others to zero.\n",
    "\n",
    "In this case, we want to keep the frequencies that are likely to be relevant to our OOK signal, and to discard the ones that aren't. This isn't necessarily a clean-cut decision. You'll have noticed in Part 3 that there's some overlap involved. Nonetheless, we can \"clean up\" our signal quite a lot by choosing cutoff frequencies strategically.\n",
    "\n",
    "Because our frequencies have physical meanings, our filter implementation will be a little more involved than the filter from Project 1b. Remember the scaling for frequencies we had to do so that we can plot spectra with accurate frequency axes? We'll need to do that here, too. So we'll first write a function that modifies a spectrum by retaining _only_ those frequencies within a _passband_, between `fmin` and `fmax`.\n",
    "\n",
    "(On the other hand, we only have to deal with one dimension in this one!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02da9fd537fb851",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.1.</span> Write a function `bandpass()` that takes a spectrum (as returned by `rfft()`) and sampling frequency `fs`, and returns the same spectrum with all values outside the frequency range between `fmin` and `fmax` set to zero.\n",
    "\n",
    "- The tricky part of this function is that you'll need to “convert” `fmin` and `fmax` to indices of the `spectrum` vector. To do this, recall from earlier that\n",
    "  $$f[n] = \\frac{f_s}{L} \\cdot n,$$\n",
    "  where $f_s$ is the sampling frequency and $L$ is the length of the original vector. Note that $L$ is **twice the length of the spectrum**.\n",
    "- Your function should not need to use `rfft()` or `irfft()`, because it is only working in the frequency domain. In subsequent cells, call these functions separately to `bandpass()`.\n",
    "- If you use `np.zeros()` (or a similar function) to initialize a new array, add the keyword argument `dtype=complex`. This will make sure the array expects to take complex numbers, since the spectrum is complex.\n",
    "- You shouldn't need to modify any of the complex numbers in the array, other than to replace them with zero.\n",
    "- Note that your filter can either include or exclude $f_\\text{min}$ and $f_\\text{max}$. We will not be strict about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7367b337dd26d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:16.754951Z",
     "start_time": "2025-05-22T21:08:16.751789Z"
    }
   },
   "outputs": [],
   "source": [
    "def bandpass(spectrum, fs, fmin, fmax):\n",
    "    # replace this line\n",
    "    return np.zeros(spectrum.size, dtype=complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907c6d6-7f05-4253-8ac2-d988ca3b21bd",
   "metadata": {},
   "source": [
    "You can check your implementation using the below cell.\n",
    "After the bandpass, the spectrum should look like the original between 5000 and 10,000 Hz, and zero everywhere else.\n",
    "Note that the input to `bandpass` is complex-valued!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53ced0-0815-40c6-a8e6-f2fc18737558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell and look at the plots\n",
    "test_freqs = rfftfreq(1000, 1 / fs)\n",
    "test_og_fft = 7000**2/(-test_freqs**2 + 7000j*test_freqs/3 + 7000**2)\n",
    "test_bandpass_fft = bandpass(test_og_fft, fs, 5000, 10000)\n",
    "fig0 = plt.figure()\n",
    "plt.plot(test_freqs, np.abs(test_og_fft))\n",
    "plt.xlabel('frequency (Hz)')\n",
    "plt.title(\"Before bandpass\")\n",
    "fig1 = plt.figure()\n",
    "plt.plot(test_freqs, np.abs(test_bandpass_fft))\n",
    "plt.title(\"After bandpass\")\n",
    "plt.xlabel('frequency (Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04500a32f79bb70",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.2</span> Apply the bandpass filter to the spectrum of your noisy signal `y` from Question 3.1. Recall that this was the output from `channel0`. Plot the resulting filtered signal in both the time domain and the frequency domain. You should use this plot to verify that your `bandpass()` implementation works as intended.\n",
    "\n",
    "You'll need to choose the cutoff frequencies `fmin` and `fmax`. You should choose them based on what you notice about the spectra in Part 3, and the definition of the approximate band we learnt in class.\n",
    "\n",
    "<div class=\"alert alert-warning\">Note that the noisy signal in Question 3.1 is free from \"interference,\" such as human talking noise introduced in Question 3.4, so filtering is unnecessary for decoding. You can use a simple energy-based decoder as in Project 2a. The intention of this question is primarily to serve as a sanity check to your filtering implementation. However, in the following questions where the received signal is affected by human voice contamination, filtering should enhance your decoding. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32453f7f1908fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:16.851075Z",
     "start_time": "2025-05-22T21:08:16.826959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 4.2.\n",
    "# Plots of filtered signal in time and frequency domain.\n",
    "y_filtered = None #name for the filtered time domain signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e06c644956fa4",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.3</span> If you haven't already, zoom in to a section of the time-domain signal that's about 10 to 15 symbols long. Plot both the unfiltered received signal, and the filtered signal (on different axes), in the same zoomed-in section.\n",
    "(If you did this during Question 4.2., just leave a note in the answer below telling us to look above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266a0e0d5eefeb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:08:17.372577Z",
     "start_time": "2025-05-22T21:08:17.369730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question 4.3\n",
    "# Plots of unfiltered and filtered signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6ccda-458e-4582-970a-9205d06fed2b",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.4</span> Listen to the original received signal `y` and the filtered received signal `y_filtered`. What sounds different?\n",
    "\n",
    "_WHAT WE EXPECT_: a short answer with 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294df27-1636-47c2-a322-f07ea0191865",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34a128-ab2d-421d-8013-c4543d32d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e29158-6fd8-4a2b-b698-844af1c804d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y_filtered, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe30b441ecdba2c",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.5</span> How did you end up choosing your filter cutoff frequencies? Explain your thinking.\n",
    "\n",
    "_WHAT WE EXPECT:_ a short answer with 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5160111da0a8c",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f9fabf2f2d86a",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.6</span> Decode the _filtered_ signal using the same techniques that you used in Project 2a. Report the bit error rate. We have given you the required helper functions; you may replace them with your own implementation from Project 2a.\n",
    "\n",
    "<div class=\"alert alert-success\"><strong>General note:</strong> You might find it helpful to plot the received signal and visualize the energy values, possibly after zooming in. This can help you find any bugs in the code, or to set the thresholds at an appropriate level. You should check this whenever you make any major changes to the parameters, or when you can't properly understand why you are getting bad performance.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3022ff2f70b3e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T21:17:55.066840Z",
     "start_time": "2025-05-22T21:17:55.052144Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(signal: np.ndarray, start_threshold, start_idx, end_idx) -> None:\n",
    "    \"\"\" Gives a visualization of where your threshold and given indices are in relation to the signal.\n",
    "    You can use this to debug how you detect your first sample, or to see if you have the right samples corresponding to each bit.\n",
    "    \"\"\"\n",
    "    plt.plot(signal, label=\"signal\")\n",
    "    if start_threshold is not None:\n",
    "        plt.axhline(start_threshold, ls='--', label=\"start threshold\", c='C1')\n",
    "    if start_idx is not None:\n",
    "        plt.axvline(start_idx, label=\"start\", c='C2')\n",
    "    if end_idx is not None:\n",
    "        plt.axvline(end_idx, label=\"end\", c='C2')\n",
    "    plt.legend()\n",
    "    \n",
    "def detect_start(signal, visual_test=False):\n",
    "    # you should define start_threshold and start_index as explained above\n",
    "    absolute_values = np.abs(signal)\n",
    "    rms = np.sqrt(np.mean(signal ** 2))\n",
    "    start_threshold = rms*np.sqrt(2)\n",
    "    start_index = np.nonzero(absolute_values > start_threshold)[0][0]\n",
    "\n",
    "    if visual_test:\n",
    "        visualize(signal, start_threshold, start_index, None)\n",
    "    return start_index\n",
    "\n",
    "\n",
    "def demodulate(signal: np.ndarray, rate: float, length: int) -> np.ndarray:\n",
    "    \"\"\" Demodulate the receieved signal\n",
    "    Input variables:\n",
    "        - signal:  1-D array of ints\n",
    "        - rate:    data rate in bits per second\n",
    "        - length   expected length of message\n",
    "    Output variables:\n",
    "        - decoded: modulated signal as 1-D array of floats\n",
    "    \"\"\"\n",
    "    start_index = detect_start(signal, visual_test=False)\n",
    "    bit_threshold = np.mean(signal[start_index:] ** 2) / 2\n",
    "\n",
    "    decoded = np.zeros(length, dtype = np.int8)\n",
    "    for i in range(length):\n",
    "        start = (i * fs) // rate + start_index\n",
    "        end = ((i + 1) * fs) // rate + start_index\n",
    "        power = np.mean(signal[int(start): int(end)] ** 2)\n",
    "        decoded[i] = 1 if (power > bit_threshold) else 0\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b40a4-4664-43c8-adf7-e18940448d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code for Question 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbea84a-401b-4f53-bda3-621e3c225593",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.7</span> Filter `y_talking`, which was the output of `channel1` in Question 3.4. Listen to the original and filtered received signals. Describe how the signal has changed.\n",
    "\n",
    "_WHAT WE EXPECT_: a short answer with 1-2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf9030-0668-4370-b8b6-95f1d7de93be",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e347e6a-cc55-4686-80a4-0e0d55975da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### YOUR CODE HERE ######\n",
    "###########################\n",
    "ipd.Audio(y_talking_filtered, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e072b4-084a-4037-8bf9-b4d0aa3d04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(y_talking, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3610fe-cd6c-4751-81a9-59c42dd4c06a",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question 4.8</span> Decode the message using the filtered version of `y_talking`. Report the bit error rate. There should be a significant improvement over the results for channel1 in project 2a, and at most 0.05 (5%). If you are getting very high error rates (~0.5), you may want to rerun Question 3.4, and generate a new `y_talking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a438d7-599d-413a-8921-c7314b66ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### YOUR CODE HERE ######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c74848b16f572c",
   "metadata": {},
   "source": [
    "# Analysis (5 points)\n",
    "\n",
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question A1.</span> For what kinds of noise or interference would the filtering strategy we implemented in this project _not_ be effective? What sort of coordination might be necessary if there are multiple transmitters operating in the same space?\n",
    "\n",
    "_WHAT WE EXPECT:_ a paragraph explaining your thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5ab66dee57f23",
   "metadata": {},
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0523a58b2d096",
   "metadata": {},
   "source": [
    "# Reflection (5 points)\n",
    "\n",
    "<span style=\"background-color: #8C1515; font-weight: bold; color: white;\">Question R1.</span> Here it is: https://forms.gle/wcizU7zJp3CLqvQC7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6cb09bb5188af2",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> Submission guidelines</font>\n",
    "\n",
    "## Export this Jupyter notebook as a PDF file\n",
    "\n",
    "- After finishing all the questions, make sure they display properly.\n",
    "- Save this notebook as a pdf file. Feel free to use any method for exporting the PDF, provided that the resulting document remains readable. Below are a few options:\n",
    "\n",
    "    1. We suggest the simplest approach: save the notebook as an HTML file, open it in a web browser, then right-click the page and select \"Print\" to generate a PDF.\n",
    "    2. Another way to convert your .ipynb files to .pdf is to upload the .ipynb file to Google Drive, and then double-clicking the file to open it in Google Colaboratory. You should see that all of your code and code outputs are there. **Please be sure to not run any cells on Colab, as this will overwrite your output!** You can then click File > Print, and then select Save as PDF in the print dialog.\n",
    "    3. You can also convert your notebook in the following websites:\n",
    "        - https://onlineconvertfree.com/convert/ipynb/\n",
    "        - https://2pdf.com/convert-ipynb-to-pdf/\n",
    "\n",
    "## What and where to submit\n",
    "\n",
    "Submit this Jupyter notebook  and the PDF to Gradescope. There are two portals, one for the PDF and the other for the notebook. We won't use the autograder this time, so the `.ipynb` notebook will only be used when we need to verify the correctness of your code.\n",
    "\n",
    "\n",
    "- Submit this Jupyter notebook file (as a .ipynb file) to the \"**Project 2b (jupyter-notebook)**\" assignment on Gradescope.\n",
    "- Submit the PDF to the \"**Project 2b (PDF)**\"\n",
    "- Don't forget to fill out the reflection form!\n",
    "\n",
    "\n",
    "## Coding style and formatting (5 points)\n",
    "\n",
    "- Coding style: This isn't a development project, so we don't plan to be very particular about this. But we still have to read your code, so please try to make that reasonably painless for us. For example, please remove commented-out code and redundant variables before you submit.\n",
    "\n",
    "- Formatting: In addition to coding style, please make sure that your exported PDF is readable (for example, your submission shouldn't be a long, single-paged PDF file) and that all the questions are properly tagged. Hopefully these 5 points will be effectively free points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
